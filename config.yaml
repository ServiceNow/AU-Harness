dataset_metric:
  - "(alpaca_audio_test, llm_judge_detailed)"
  - "(aishell_1_test, word_error_rate)"
  - "(audiocaps_qa_test, llm_judge_detailed)"
  - "(audiocaps_test, llm_judge_detailed)"
  - "(clotho_aqa_test, llm_judge_detailed)"
  - "(cn_college_listen_mcq_test, word_error_rate)"
  - "(common_voice_15_en_test, word_error_rate)"
  - "(covost2_ta_en_test, word_error_rate)"
  - "(covost2_zh_en_test, word_error_rate)"
  - "(covost2_id_en_test, word_error_rate)"
  - "(covost2_en_ta_test, word_error_rate)"
  - "(covost2_en_zh_test, word_error_rate)"
  - "(covost2_en_id_test, word_error_rate)"
  - "(dream_tts_mcq_test, word_error_rate)"
  - "(gigaspeech_test, word_error_rate)"
  - "(gigaspeech2_id_test, word_error_rate)"
  - "(gigaspeech2_th_test, word_error_rate)"
  - "(gigaspeech2_vi_test, word_error_rate)"
  - "(iemocap_emotion_recognition, llm_judge_binary)"
  - "(iemocap_gender_recognition, llm_judge_binary)"
  - "(librispeech_test_clean, word_error_rate)"
  - "(librispeech_test_other, word_error_rate)"
  - "(meld_emotion_test, llm_judge_binary)"
  - "(meld_sentiment_test, llm_judge_binary)"
  - "(mmau_mini, llm_judge_binary)"
  - "(mnsc_asr_part1_test, word_error_rate)"
  - "(mnsc_asr_part2_test, word_error_rate)"
  - "(mnsc_asr_part3_test, word_error_rate)"
  - "(mnsc_asr_part4_test, word_error_rate)"
  - "(mnsc_asr_part5_test, word_error_rate)"
  - "(mnsc_asr_part6_test, word_error_rate)"
  - "(mnsc_pqa_ar_dialogue_test, llm_judge_binary)"
  - "(mnsc_pqa_ar_sentence_test, llm_judge_binary)"
  - "(mnsc_pqa_gr_dialogue_test, llm_judge_binary)"
  - "(mnsc_pqa_gr_sentence_test, llm_judge_binary)"
  - "(mnsc_sds_part3_test, llm_judge_detailed)"
  - "(mnsc_sds_part4_test, llm_judge_detailed)"
  - "(mnsc_sds_part5_test, llm_judge_detailed)"
  - "(mnsc_sqa_part3_test, llm_judge_detailed)"
  - "(mnsc_sqa_part4_test, llm_judge_detailed)"
  - "(mnsc_sqa_part5_test, llm_judge_detailed)"
  - "(mnsc_sqa_part6_test, llm_judge_detailed)"
  - "(mu_chomusic_test, llm_judge_binary)"
  - "(openhermes_instruction_test, llm_judge_detailed)"
  - "(peoples_speech_test, word_error_rate)"
  - "(public_sg_speech_qa_test, llm_judge_detailed)"
  - "(seame_dev_sge, word_error_rate)"
  - "(slue_p2_sqa5_test, llm_judge_binary)"
  - "(spoken_squad_test, llm_judge_binary)"
  - "(tedlium3_test, word_error_rate)"
  - "(tedlium3_long_form_test, word_error_rate)"
  - "(voxceleb_accent_test, llm_judge_binary)"
  - "(voxceleb_gender_test, llm_judge_binary)"
  - "(wavcaps_qa_test, llm_judge_detailed)"
  - "(wavcaps_test, llm_judge_detailed)"
  
judge_concurrency: 8
judge_model: "gpt-4o-mini"

models:
  - info:
      name: "qwen_2_audio"
      inference_type: "vllm"
      url: "https://67d45bd7-c3a9-46b8-9991-107a462f67b2-8000.job.console.elementai.com/v1"
      delay: 100
      retry_attempts: 8
      timeout: 30
      model: "qwen_2_audio"
      auth_token: "8o30OElfDYV_D6YbbznT0A:GDC2BsXIfSdfjv9iWka3V4MkazpvHfe0cCwXohzbP0Q"
      batch_size: 50
      chunk_size: 30