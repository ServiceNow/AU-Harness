#inference server types
INFERENCE_SERVER_VLLM_CHAT_COMPLETION = "vllm"
OPENAI_CHAT_COMPLETION = "openai"
INFERENCE_SERVER_VLLM_TRANSCRIPTION = "vllm_transcription"
OPENAI_TRANSCRIPTION = "openai_transcription"
#extras
ROUND_DIGITS = 3
INVERTED_METRIC_INDICATOR = "â†“"
